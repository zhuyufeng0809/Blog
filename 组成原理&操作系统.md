### 高速缓存

* 为了弥补处理器与主内存处理速度之间的鸿沟，硬件设计者在主内存和处理器之间引人了**高速缓存（Cache）**，高速缓存是一种存取速率远比主内存大而容量远比主内存小的存储部件
* 引人高速缓存之后，处理器在执行内存读、写操作的时候并不直接与主内存打交道，而是通过高速缓存进行
* 变量名相当于内存地址，而变量值则相当于相应内存空间所存储的数据，高速缓存相当于为进程所访问的每个变量保留了一份相应内存空间所存储数据（变量值）的副本
* 由于高速缓存的存储容量远小于主内存，因此高速缓存并不是每时每刻保留着所有变量值的副本
* 高速缓存相当于一个由硬件实现的容量极小的散列表（Hash Table），其键（Key）是一个内存地址，其值（Value）是内存数据的副本或者准备写人内存的数据。从内部结构来看，高速缓存相当于一个拉链散列表（Chained Hash Table），它包含若干桶（Bucket，硬件上称之为Set），每个桶又可以包含若干缓存条目（Cache Entry），缓存条目可被进一步划分为Tag、DataBlock以及Flag这三个部分
    * DataBlock也被称为缓存行（CacheLine），它是高速缓存与主内存之间的数据交换最小单元，用于存储从内存中读取的或者准备写往内存的数据，一个缓存行可以存储若干变量的值，而多个变量的值则可能被存储在同一个缓存行之中
    * Tag包含了与缓存行中数据相应的内存地址的部分信息（内存地址的高位部分比特）
    * Flag用于表示相应缓存行的状态信息
* 处理器在执行内存访问操作时会将相应的内存地址解码。内存地址的解码结果包括tag、index以及offset这三部分数据
    * index相当于桶编号，它可以用来定位内存地址对应的桶，一个桶可能包含多个缓存条目
    * tag相当于缓存条目的相对编号，其作用在于用来与同一个桶中的各个缓存条目中的Tag部分进行比较，以定位一个具体的缓存条目
    * 一个缓存条目中的缓存行可以用来存储多个变量，offset是缓存行内的位置偏移，其作用在于确定一个变量在一个缓存行中的存储起始位置
* 根据内存地址的解码结果，如果在高速缓存中能够找到相应的缓存行并且缓存行所在的缓存条目的Flag表示相应缓存条目是有效的，那么就称相应的内存操作产生了缓存命中（CacheHit）；否则，就称相应的内存操作产生了缓存未命中（Cache Miss）。缓存未命中包括读未命中（Read Miss）和写未命中（Write Miss），分别对应内存读和写操作
    * 当产生读未命中时，处理器所需读取的数据会从主内存中加载并被存人相应的缓存行之中。这个过程会导致处理器停顿（Stall）而不能执行其他指令，这不利于发挥处理器的处理能力。因此，从性能的角度来看应该尽可能地减少缓存未命中
    * 由于高速缓存的总容量远小于主内存的总容量，同一个缓存行在不同时刻存储的可能是不同的一段数据，因此缓存未命中是不可避免的
* 现代处理器一般具有多个层次的高速缓存，相应层级的高速缓存通常被称为一级缓存（L1 Cache）、二级缓存（L2 Cache）、三级缓存（L3 Cache），多核CPU里的每一个CPU核，都有独立的属于自己的L1 Cache和L2 Cache。多个CPU之间，共用L3 Cache和主内存
    * 一级缓存被直接集成在处理器的内核（Core）里，每个核上都有一个L1缓存，因此其访问效率非常高，一级缓存通常包括两部分，其中一部分用于存储指令（L1i），另外一部分用于存储数据（L1d）
    * L2缓存更大一些，速度要慢一些，一般情况下每个核上都有一个独立的L2缓存
    * L3缓存是三级缓存中最大的一级，同时也是最慢的一级, 在同一个CPU插槽之间的核共享一个L3缓存
* 距离处理器越近的高速缓存，其存取速率越快，制造成本越高，因此其容量也越小。距离处理器越远（即距离主内存越近）的高速缓存，其存储速率会越慢，而存储容量则相应地增大
* 读取数据过程：就像数据库缓存一样，首先在最快的缓存中找数据，如果缓存没有命中(Cache miss)则往下一级找，直到三级缓存都找不到时，向内存要数据。一次次地未命中，代表取数据消耗的时间越长
* 计算过程：程序以及数据被加载到主内存；指令和数据被加载到CPU的高速缓存；CPU执行指令，把结果写到高速缓存；高速缓存中的数据写回主内存

### 缓存一致性协议
多核CPU的每个核有各自的一级和二级缓存，一个核对其副本数据进行更新之后，其他核如何“察觉”到该更新并做出适当反应，以确保这些核后续读取该共享变量时能够读取到这个更新，这就是缓存一致性问题，为了解决这个问题，处理器之间需要一种通信机制一缓存一致性协议（Cache Coherence Protocol）  

MESI（Modified-Exclusive-Shared-Invalid）协议是一种广为使用的缓存一致性协议，x86处理器所使用的缓存一致性协议就是基于MESI协议的。MESI协议要求对同一地址的读内存操作是并发的，而针对同一地址的写内存操作是独占的，即针对同一内存地址进行的写操作在任意一个时刻只能够由一个核执行。在MESI协议中，一个处理器往内存中写数据时必须持有该数据的所有权  

为了保障数据的一致性，MESI将缓存条目的状态划分为Modified、Exclusive、 Shared和Invalid这 4种，并在此基础上定义了一组消息（Message）用于协调各个处理器的读、写内存操作。MESI协议中一个缓存条目的Flag值有以下4种可能

| 状态 | 描述 |
| :----: | :----: |
| M（Modified）| 该状态表示相应缓存行有效。该状态表示相应缓存行包含对相应内存地址所做的更新结果数据。由于MESI协议中的任意一个时刻只能够有一个核对同一内存地址对应的数据进行更新，因此在多核处理器的高速缓存中Tag值相同的缓存条目中，任意一个时刻只能够有一个缓存条目处于该状态，且其他所有核上的高速缓存当前都不保留该数据的有效副本。缓存行中包含的数据与主内存中包含的数据不一致 |
| E（Exclusive）| 该状态表示相应缓存行有效。该缓存行以独占的方式保留了相应内存地址的副本数据，即其他所有核上的高速缓存当前都不保留该数据的有效副本。缓存行中包含的数据与主内存中包含的数据一致|
| S（Shared）| 该状态表示相应缓存行有效。其他核上的高速缓存中也**可能**存在相同内存地址对应的副本数据，其他副本缓存条目的状态也为Shared。缓存行中包含的数据与主内存中包含的数据一致|
| I（Invalid）| 该状态表示相应缓存行无效。该状态是缓存条目的初始状态 |

MESI协议定义了一组消息（Message）用于协调各个处理器的读、写内存操作。可以将MESI协议中的消息分为请求消息和响应消息。处理器核心在执行内存读、写操作时在必要的情况下会往总线（Bus）中发送特定的请求消息，同时每个处理器核心还嗅探（Snoop，也称拦截）总线中由其他处理器核心发出的请求消息并在一定条件下往总线中回复相应的响应消息

| 状态 | 消息类型 | 描述 |
| :----: | :----: | :----: |
| Read | 请求 | 通知其他处理器核心、主内存当前处理器核心准备读取某个数据。该消息包含待读取数据的内存地址 |
| Read Response | 响应 | 该消息包含被请求读取的数据。该消息可能是主内存提供的，也可能是嗅探 Read消息的其他高速缓存提供的 |
| Invalidate | 请求 | 通知其他处理器核心将其高速缓存中指定内存地址对应的缓存条目状态置为I，即通知这些处理器核心删除指定内存地址的副本数据 |
| Invalidate Acknowledge | 响应 | 接收到Invalidate消息的处理器核心必须回复该消息，以表示删除了其高速缓存上的相应副本数据 |
| Read Invalidate | 请求 | 该消息是由Read消息和Invalidate消息组合而成的复合消息。用于通知其他处理器核心当前处理器准备更新（Read-Modify-Write，读后写更新）一个数据，并请求其他处理器核心删除其高速缓存中相应的副本数据。接收到该消息的处理器核心必须回复Read Response消息和Invalidate Acknowledge消息 |
| Writeback | 请求 | 该消息包含需要写入主内存的数据及其对应的内存地址 |

#### 读过程
发起读操作的CPU核心会根据地址找到对应的缓存条目，读取该缓存条目的Flag值（缓存条目状态），如果找到的缓存条目的状态如果为M、E或者S，那么该CPU核心可以直接从相应的缓存行中读取地址所对应的数据，而无须往总线中发送任何消息。如果该CPU核心找到的缓存条目的状态如果为I，则说明该CPU核心的高速缓存中并不包含有效副本数据，此时该CPU核心需要往总线发送Read消息以读取地址对应的数据，而其他CPU核心（或者主内存）则需要回复Read Response以提供相应的数据。发起读操作的CPU核 心接收到Read Response消息时，会将其中携带的数据（包含数据的数据块）存人相应的缓存行并将相应缓存条目的状态更新为S。该CPU核心接收到的Read Response消息可能来自主内存也可能来自其他CPU核心

* 如果其他CPU核心嗅探到Read消息时，找到的相应缓存条目的状态为M，那么其他CPU核心在往总线发送Read Response消息前将相应缓存行中的数据写入主内存，再发送Read Response消息。其他CPU核心往总线发送Read Response之后，相应缓存条目的状态会被更新为S
* 如果其他CPU核心嗅探到Read消息时，找到的相应缓存条目的状态为E，那么其他CPU核心在往总线发送Read Response消息后，相应缓存条目的状态会被更新为S
* 如果其他CPU核心嗅探到Read消息时，找到的相应缓存条目的状态为I，那么发起读操作的CPU核心所接收到的Read Response消息就来自主内存

#### 写过程
任何一个CPU核心执行内存写操作时必须拥有相应数据的所有权。发起写操作的CPU核心会根据地址找到对应的缓存条目。如果发起写操作的CPU核心所找到的缓存条目的状态若为E或者M，则说明该CPU核心已经拥有相应数据的所有权，此时该CPU核心可以直接将数据写人相应的缓存行并将相应缓存条目的状态更新为M（如果本来状态就为M，则无须更新）。如果发起写操作的CPU核心所找到的缓存条目的状态如果不为E、M，则该CPU核心需要往总线发送Invalidate消息以获得数据的所有权。其他CPU核心接收到Invalidate消息后会将其高速缓存中相应的缓存条目状态更新为I（相应的副本数据置为无效）并回复Invalidate Acknowledge消息。发送Invalidate消息的CPU核心（即发起写操作的CPU核心），必须在接收到其他所有CPU核心所回复的所有Invalidate Acknowledge消息之后再将数据更新到相应的缓存行之中

* 如果发起写操作的CPU核心找到的缓存条目的状态为S，则说明其他CPU核心上的高速缓存可能也保留了地址对应的数据副本，此时发起写操作的CPU核心需要往总线发送Invalidate消息。发起写操作的CPU核心在接收到其他所有CPU核心所回复的Invalidate Acknowledge消息之后会将相应的缓存条目的状态更新为E，此时发起写操作的CPU核心获得了地址上数据的所有权。接着，发起写操作的CPU核心便可以将数据写人相应的缓存行，并将相应的缓存条目的状态更新为M
* 如果发起写操作的CPU核心找到的缓存条目的状态为I，此时该CPU核心需要往总线发送Read Invalidate消息。发起写操作的CPU核心在接收到Read Response消息以及其他所有CPU核心所回复的Invalidate Acknowledge消息之后，会将相应缓存条目的状态更新为E，这表示该CPU核心已经获得相应数据的所有权。接着，发起写操作的CPU核心便可以往相应的缓存行中写人数据了并将相应缓存条目的状态更新为M。其他CPU核心在接收到Invalidate消息或者Read Invalidate消息之后，必须根据消息中包含的内存地址在该处理器的高速缓存中查找相应的高速缓存条目。若其他CPU核心所找到的高速缓存条目的状态不为I，那么其他CPU核心必须将相应缓存条目的状态更新为I，把相应的副本数据置为无效并给总线回复Invalidate Acknowledge消息

### 写缓冲器和无效化队列
MESI协议解决了缓存一致性问题，但是存在一个性能弱点：发起写操作的CPU核心未获得相应数据的所有权时，必须等待其他所有CPU核心将其高速缓存中的相应副本数据删除并接收到这些CPU核心所回复的Invalidate Acknowledge/Read Response消息，获得相应数据的所有权之后才能将数据写人高速缓存。为了规避和减少这种等待造成的写操作的延迟（Latency），硬件设计者引入了写缓冲器和无效化队列

#### 写缓冲器
写缓冲器（Store Buffer，也被称为Write Buffer）是处理器内部的一个容量比高速缓存还小的私有高速存储部件，每个CPU核心都有其写缓冲器，写缓冲器内部可包含若干条目（Entry）。一个CPU核心无法读取另外一个CPU核心上的写缓冲器中的内容  

引入写缓冲器之后，CPU核心在执行写操作时会做这样的处理：

* 如果相应的缓存条目状态为E或者M，CPU核心可能会直接将数据写人相应的缓存行而无须发送任何消息
* 如果相应的缓存条目状态为S，CPU核心会先将写操作的相关数据（包括数据和待操作的内存地址）存入写缓冲器的条目之中，并发送Invalidate消息
* 如果相应的缓存条目状态为I，则表明相应的写操作遇到了写未命中（Write Miss），此时CPU核心会先将写操作相关数据存人写缓冲器的条目之中，并发送Read Invalidate消息。在其他所有CPU核心的高速缓存都未保存指定地址的副本数据的情况下，Read消息回复者是主内存，也就是说Read消息可能导致主内存读操作，这种情况下的写未命中开销是比较大的

发起写操作的CPU核心在将写操作的相关数据写入写缓冲器之后便认为该写操作已经完成，即该CPU核心并不等待其他CPU核心返回Invalidate Acknowledge/Read Response消息而是继续执行其他指令（比如执行读操作）。一个CPU核心接收到其他CPU核心所回复的针对同一个缓存条目的所有Invalidate Acknowledge消息的时候，该CPU核心会将写缓冲器中针对相应地址的写操作的结果写人相应的缓存行中，此时写操作对于发起写操作的CPU核心之外的其他CPU核心来说才算是完成的

#### 无效化队列
引人无效化队列（Invalidate Queue）之后，CPU核心在接收到Invalidate消息之后并不删除消息中指定地址对应的副本数据，而是将消息存人无效化队列之后就回复InvalidateAcknowledge消息，从而减少了发起写操作的CPU核心所需的等待时间  

写缓冲器和无效化队列的引人又会带来一些新的问题：内存重排序和可见性问题
#### 存储转发
引入写缓冲器之后，CPU核心在执行读操作的时候不能根据相应的内存地址直接读取相应缓存行中的数据作为该操作的结果。这是因为一个CPU核心在更新一个变量之后紧接着又读取该变量的值的时候，由于该CPU核心先前对该变量的更新结果可能仍然还停留在写缓冲器之中，因此该变量相应的内存地址所对应的缓存行中存储的值是该变量的旧值。这种情况下为了避免读操作所返回的结果是一个旧值，CPU核心在执行读操作的时候会根据相应的内存地址查询写缓冲器。如果写缓冲器存在相应的条目，那么该条目所代表的写操作的结果数据就会直接作为该读操作的结果返回；否则，CPU核心才从高速缓存中读取数据。这种CPU核心直接从写缓冲器中读取数据来实现内存读操作的技术被称为存储转发（StoreForwarding）。存储转发使得发起写操作的CPU核心能够在不影响该处理器执行读操作的情况下将写操作的结果存入写缓冲器

#### 内存重排序
写缓冲器和无效化队列都可能导致内存重排序

##### 写缓冲器可能导致StoreLoad重排序（Stores Reordered After Loads）
StoreLoad重排序是绝大多数处理器都允许的一种内存重排序

| Processor0 | Processor1 |
| :----: | :----: |
| X=1;//S1 | Y=1;//S3 |
| r1=Y;//L2 |  |
|  | r2=X;//L4 |

假设CPU核心Processor0和Processor1上的两个线程未使用任何同步措施而各自按照程序顺序并依照上表所示的线程交错顺序执行。其中变量X、Y为共享变量，其初始值均为0，r1、r2为局部变量。当Processor0上的线程执行到L2时，虽然在此之前S3已经被Processor1执行完毕，但是由于S3的执行结果可能仍然还停留在Processor1的写缓冲器中，而一个CPU核心无法读取另外一个CPU核心的写缓冲器中的内容，因此 Processor0此刻读取到的Y的值仍然是其高速缓存中存储的该变量的初始值0。同理，Processor1执行到 L4时所读取到变量X的值也可能是该变量的初始值0。因此，从Processor1的角度来看，Processor1执行L4的那一刻Processor0已经执行了L2而S1却像是尚未被执行，即Processor1对Processor0执行的两个操作的感知顺序是L2→S1，也就是说此时写缓冲器导致了S1被重排序到了L2之后

##### 写缓冲器可能导致StoreStore重排序（Stores Reordered After Stores）

| Processor0 | Processor1 |
| :----: | :----: |
| data=1;//S1 |  |
| ready=true;//S2 |  |
|  | while(!ready) continue;//L3 |
|  | print(data);//L4 |

假设CPU核心Processor0和Processor1上的两个线程未使用任何同步措施而各自按照程序顺序并依照上表所示的线程交错顺序执行。其中变量data、ready为共享变量，其初始值分别为0和false。假设Processor0执行S1、S2时该处理器的高速缓存中包含变量ready的副本但不包含变量data的副本，那么S1的执行结果会先被存入写缓冲器而S2的执行结果会直接被存人高速缓存。L3被执行时S2对ready的更新通过缓存一致性协议可以被Processor1读取到，于是，由于ready值已变为true，因此Processor1继续执行L4。L4被执行的时候，由于S1对data的更新结果可能仍然停留在ProcessorO的写缓冲器之中，因此Processor1此时读取到的变量data的值可能仍然是其初始值0，即L4的输出结果可能仍然是0而不是Processor1所期望的新值（Processor0更新之后的值）。从Processor1的角度来看，这就造成了一种现象：S2像是先于S1被执行，即S1被重排序到了S2之后

##### 无效化队列可能导致LoadLoad重排序（Loads Reordered After Loads）

| Processor0 | Processor1 |
| :----: | :----: |
| data=1;//S1 |  |
| ready=true;//S2 |  |
|  | while(!ready) continue;//L3 |
|  | print(data);//L4 |

假设CPU核心Processor0和Processor1上的两个线程未使用任何同步措施而各自按照程序顺序并依照上表所示的线程交错顺序执行。其中变量data、ready为共享变量，其初始值分别为0和false。进一步假设Processor0的高速缓存中存有变量data和ready的副本，Processor1仅存有变量data的副本而未存有变量ready的副本。那么，Processor0和Processor1有可能按照如下序列执行一系列操作：

* Processor0执行S1。此时由于Processor1上也存有变量data的副本，因此Processor0会发出Invalidate消息并将S1的操作结果存人写缓冲器
* Processor1接收到Processor0发出的Invalidate消息时将该消息存人其无效化队列并回复Invalidate Acknowledge消息
* Processor0接收到Invalidate Acknowledge消息，随即将S1的操作结果写人高速缓存。然后，Processor0执行S2。此时由于只有Processor0上存有变量ready的副本，因此Processor0无须发送任何消息，直接将S2的操作结果存人高速缓存即可
* Processor1执行L3。此时由于Processor1的高速缓存中并没有存储变量ready的副本，因此Processor1会发出一个Read消息
* Processor0接收到Processor1发出的Read消息并回复Read Response消息。由于此时Processor0已经执行过S2，因此该ReadResponse消息包含的ready变量值为true
* Processor1接收到Read Response消息并从中取出ready变量的新值，此时L3中的循环语句可以结束
* Processor1执行L4。此时，由于Processor0为了更新变量data而发出的Invalidate消息可能仍然还停留在Processor1的无效化队列中，因此Processor1从其高速缓存中读取的变量data的值仍然是其初始值。因此，L4所打印的变量值可能是一个旧值

由此可见，尽管Processor0对共享变量data，ready的更新是按照程序顺序先后到达高速缓存的，但是由于无效化队列的作用Processor1像是在ready变量不为true的情况下提前读取了变量data的值，然而，程序的实际处理逻辑是仅在ready变量值为true的情况下才读取变量data，因此这里Processor1实际读取到的变量（data）值是一个旧值。也就是说，从Processor0的角度来看，L4被重排序到了L3之前

不同的处理器架构所支持（允许）的内存重排序各有不同。比如，现代处理器都会采用写缓冲器，而有的处理器（比如x86）会保障写操作的顺序，即这些处理器不允许StoreStore重排序的出现

#### 可见性

##### 写缓冲器导致的可见性问题
写缓冲器是CPU核心内部的私有存储部件，一个CPU核心中的写缓冲器所存储的内容是无法被其他CPU核心所读取的。因此，一个CPU核心上运行的线程更新了一个共享变量之后，其他CPU核心上运行的线程再来读取该变量时这些线程可能仍然无法读取到前一个线程对该变量所做的更新，因为这个更新可能还停留在前一个线程所在的CPU核心上的写缓冲器之中。这种现象就是所谓的可见性问题。因此，硬件根源上的可见性问题一半是由写缓冲器导致的。为了使一个CPU核心上运行的线程对共享变量所做的更新可以被其他CPU核心上运行的其他线程所读取，必须将写缓冲器中的内容写入其所在的CPU核心上的高速缓存之中，从而使该更新在缓存一致性协议的作用下可以被其他CPU核心读取到  

CPU核心在一些特定条件下（比如写缓冲器满、I/O指令被执行）会将写缓冲器排空（Drain）或者冲刷（Flush），即将写缓冲器中的内容写入高速缓存，但是从程序对一个或者一组变量更新的角度来看，CPU核心本身并不保证这种冲刷对程序来说是“及时”的。因此，为了保证一个CPU核心对共享变量所做的更新可以被其他CPU核心同步，编译器等底层系统需要借助一类被称为内存屏障的特殊指令。内存屏障中的存储屏障（Store Barrier）可以使执行该指令的CPU核心冲刷其写缓冲器

##### 无效化队列导致的可见性问题
硬件根源上可见性问题的另一半是由无效化队列导致的。无效化队列的引入本身也会导致新的问题：CPU核心在执行内存读取操作前如果没有根据无效化队列中的内容将该CPU核心上的高速缓存中的相关副本数据删除，那么就可能导致该CPU核心读到的数据是过时的旧数据，从而使得其他CPU核心所做的更新丢失。因此。为了使一个CPU核心运行的线程能够读取到另外一个CPU核心上运行的线程对共享变量所做的更新，该CPU核心必须先根据无效化队列中存储的Invalidate消息删除其高速缓存中的相应副本数据，从而使其他CPU核心上运行的线程对共享变量所做的更新在缓存一致性协议的作用下能够被同步到该CPU核心的高速缓存之中。内存屏障的加载屏障（Load Barrier）正是用来解决这个问题的。加载屏障会根据无效化队列内容所指定的内存地址，将相应CPU核心上的高速缓存中相应的缓存条目的状态都标记为I，从而使该CPU核心后续执行针对相应地址（无效化队列内容中指定的地址）的读内存操作时必须发送Read消息，以将其他CPU核心对相关共享变量所做的更新同步到该CPU核心的高速缓存中

##### 存储转发导致的可见性问题
假设CPU核心Processor0在t1时刻更新了某个共享变量，随后又在t2时刻读取了该变量。在t1时刻到t2时刻之间的这段时间内其他CPU核心可能已经更新了该共享变量，但是如果t2时刻Processor0在t1时刻所做的更新仍然停留在该CPU核心的写缓冲器之中，那么存储转发技术会使Processor0直接从其写缓冲器读取该共享变量的值。也就是说Processor0此时根本不从高速缓存中读取该变量的值，这就使得另外一个CPU核心对该共享变量所做的更新无法被该CPU核心读取，从而导致Processor0在t2时刻读取到的变量值是一个旧值。因此，考虑到存储转发技术的这个副作用，从读线程的角度来看，为了使读线程能够将其他线程对共享变量所做的更新同步到该线程所在的CPU核心的高速缓存中，需要清空该CPU核心上的写缓冲器（先）以及无效化队列（后）  

因此，解决可见性问题首先要使写线程所在的CPU核心对共享变量所做的更新能够到达（被存储到）高速缓存，从而使该更新对其他CPU核心是可同步的。其次，读线程所在的CPU核心要将其无效化队列中的内容“应用”到其高速缓存上，这样才能够将其他CPU核心对共享变量所做的更新同步到该CPU核心的高速缓存中。而这两点是通过存储屏障与加载屏障的成对使用实现的：写线程的执行CPU核心所执行的存储屏障保际了该线程对共享变量所做的更新对读线程来说是可同步的；读线程的执行CPU核心所执行的加载屏障将写线程对共享变量所做的更新同步到该CPU核心的高速缓存之中

### 基本内存屏障
处理器支持（允许）哪种内存重排序（LoadLoad重排序、LoadStore重排序、StoreStore重排序、StoreLoad重排序），就会提供能够禁止相应重排序的指令，这些指令就被称为**基本内存屏障**

* LoadLoad屏障
* LoadStore屏障
* StoreStore屏障
* StoreLoad屏障

基本内存屏障可以统一用XY来表示，其中的X和Y可以代表Store和Load。基本内存屏障是对一类指令的称呼，这类指令的作用是禁止该指令左侧的任何X操作与该指令右侧的任何Y操作之间进行重排序，从而确保该指令左侧的所有X操作先于该指令右侧的Y操作被提交，即内存操作作用到高速缓存（或者主内存）上

| 屏障名称 | 示例指令序列 | 具体作用 |
| :----: | :----: | :----: |
| StoreLoad | Store1;Store2;Store3;**StoreLoad**;Load1;Load2;Load3 | 禁止StoreLoad重排序，即确保该屏障之前的任何一个写操作（比如Store2）的结果都会在该屏障之后的任何一个读操作（比如Load1）的数据被加载之前对其他CPU核心来说是可同步的 |
| StoreStore | Store1;Store2;Store3;**StoreStore**;Store4;Store5;Store6 | 禁止StoreStore重排序，即确保该屏障之前的任何一个写操作（比如Store1）的结果都会在该屏障之后的任何一个写操作（比如Store4）之前对其他CPU核心来说是可同步的 |
| LoadLoad | Load1;Load2;Load3;**LoadLoad**;Load4;Load5;Load6 | 禁止LoadLoad重排序，即确保该屏障之前的任何一个读操作（比如Load1）的数据都会在该屏障之后的任何一个读操作（比如Load4）之前被加载 |
| LoadStore | Load1;Load2;Load3;**LoadStore**;Store1;Store2;Store3; | 禁止LoadStore重排序，即确保该屏障之前的任何一个读操作（比如Load1）的数据都会在该屏障之后的任何一个写操作（比如Store1）的结果被冲刷（写入）到高速缓存（或者主内存）之前被加载 |

基本内存屏障的作用只是保障其左侧的X操作先于其右侧的Y操作被提交，它并不全面禁止重排序。**XY屏障两侧的内存操作仍然可以在不越过内存屏障本身的情况下在各自的范围内进行重排序，并且XY屏障左侧的非X操作与屏障右侧的非Y操作之间仍然可以进行重排序（即越过内存屏障本身）**。例如，在Store1;Load1;Store2;**StoreLoad**;Store3;Load2;Load3指令序列中，Load2、Load3和Store1、Store2之间无法进行重排序，而Store1、Load1和Store2之间可以重排序，Store3、Load2和Load3之间可以重排序，Load1和Store3之间也可以进行重排序  

内存屏障需要编译器（JIT编译器）、运行时（Java虚拟机）和处理器等多方的尊重，才能保障其作用得以落实  

LoadLoad屏障是通过清空无效化队列来实现禁止LoadLoad重排序的。LoadLoad屏障会使其执行CPU核心根据无效化队列中的Invalidate消息删除其高速缓存中相应的副本。这个过程被称为将无效化队列应用到高速缓存，也被称为清空无效化队列，它使CPU核心有机会将其他CPU核心对共享变量所做的更新同步到该CPU核心的高速缓存中，从而消除了LoadLoad重排序的根源而实现了禁止LoadLoad重排序  

StoreStore屏障可以通过对写缓冲器中的条目进行标记来实现禁止StoreStore重排序。StoreStore屏障会将写缓冲器中的现有条目做一个标记，以表示这些条目代表的写操作需要先于该屏障之后的写操作被提交。CPU核心在执行写操作的时候如果发现写缓冲器中存在被标记的条目，那么即使这个写操作对应的高速缓存条目的状态为E或者M，此时处理器也不直接将写操作的数据写入高速缓存，而是将其写入写缓冲器，从而使得StoreStore屏障之前的任何写操作先于该屏障之后的写操作被提交  

就处理器的具体实现而言，许多处理器往往将StoreLoad屏障实现为一个通用基本内存屏障（General-purpose Barrier），即StoreLoad屏障能够实现其他3种基本内存屏障的效果。StoreLoad屏障能够替代其他基本内存屏障，但是它的开销也是最大的：StoreLoad屏障会清空无效化队列，并将写缓冲器中的条目冲刷（写入）高速缓存。因此，StoreLoad屏障既可以将其他CPU核心对共享变量所做的更新同步到该CPU核心的高速缓存中，又可以使其执行CPU核心对共享变量所做的更新对其他CPU核心来说可同步

https://www.cnblogs.com/valjeanshaw/p/11469514.html
https://blog.csdn.net/qyf__123/article/details/100904595

https://www.cnblogs.com/yanlong300/p/8986041.html
https://blog.csdn.net/unei66/article/details/25738977

https://blog.csdn.net/qq_35494088/article/details/79845240
https://www.jianshu.com/p/64240319ed60

https://blog.csdn.net/qq_25330791/article/details/105551921

https://www.cnblogs.com/kaleidoscope/p/9598140.html